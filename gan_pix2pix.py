# -*- coding: utf-8 -*-
"""GAN_Pix2Pix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Jq85vIXlLFITbaSsMIR1o8BwVs1F-z2
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

import os

"""# Pix2Pix

This notebook implements the Pix2Pix paper that addresses the image-to-image translation problem. The goal is to translate from an image of one type to another. This implemetation follows the structure of the offical tutorial from Tensorflow.

+ [Paper](https://arxiv.org/pdf/1611.07004.pdf)
+ [TensorFlow Official Tutorial](https://www.tensorflow.org/tutorials/generative/pix2pix)

We download the data, build input pipeline, construct the generator + disciminator, train the model with GAN + L1 loss, and generate images 
"""

data_path = tf.keras.utils.get_file('facades.tar.gz', 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz', untar=True)
dir_path = os.path.dirname(data_path)

"""# Input Pipeline

We use the tf.data API to build the input pipeline.      
For the training set, we augment the data by randomly cropping and horizonally flipping the images. 
"""

def process_image(img_path, mode='train'):
    # Reads images from image path and convert to the 0-1 scale
    img = tf.image.decode_jpeg(tf.io.read_file(img_path))
    img = tf.cast(img, tf.float32) / 255.0

    # Separates into the input-output pairs
    y = img[:, :256, :]
    x = img[:, 256:, :]

    # Augments the training set with crop + flip
    if mode == 'train':
        concat_x_y = tf.concat([x, y], axis=-1)
        concat_x_y = tf.image.resize(concat_x_y, size=(300, 300))
        concat_x_y = tf.image.random_crop(concat_x_y, size=(256, 256, 6))
        if tf.random.uniform(shape=()) > 0.5:
            concat_x_y = tf.image.flip_left_right(concat_x_y)

        x =  concat_x_y[..., :3]
        y =  concat_x_y[..., 3:]

    return x, y

def build_ds(mode='train'):
    # Gets an image directory
    img_dir = os.path.join(dir_path, 'facades', mode)

    # Loads + transform data directly from an image directory
    ds = tf.data.Dataset.list_files(img_dir + '/*.jpg')
    return ds.map(lambda img_path: process_image(img_path, mode=mode))

# Builds the train, val, and test sets
train_ds = build_ds(mode='train')
val_ds = build_ds(mode='val')
test_ds = build_ds(mode='test')

"""Several examples of the training dataset"""

for x, y in train_ds.batch(5).take(3):
    print('*'*100)
    plt.imshow(x[0]); plt.show()
    plt.imshow(y[0]); plt.show()

"""# Models

We need to build a generator to tranlate from images to images. One of the critical specifications for the generator is that the generated images must "look real". I like the ideal that Ian Goodfellow can quantify the abstract concept of "looking real" from the GAN training and loss.

## Generators

The neural architecture for the generator follows the U-net. We declare the model, show the distribution of the output, and depict the computational graph.
One of the mistakes that I made was on missing the activation layer at the last stage of the transpose convolution.

Taking another perspective, this is the moment when AI can actually "***draw images***".
"""

# Variables for the shape of the U-net
dim_nfilters_map = dim_nfilters_map = {
    128: 32, 
    64: 64, 
    32: 128, 
    16: 256, 
    8: 256, 
    4: 256, 
    2:256, 
    1: 256
}

class Generator(tf.keras.Model):
    def __init__(self,
                 dim_nfilters_map = dim_nfilters_map,
                 activation_conv=tf.keras.layers.LeakyReLU(alpha=0.1),
                 activation_conv_t=tf.keras.layers.ReLU(),
                 kernel_size=3,
                 rate=0.3):
        super().__init__()

        # Use string keys to ease the saved model in the later part
        self.dim_nfilters_map = {
            str(d): f for d, f in dim_nfilters_map.items()
        }
        self.dims = sorted(self.dim_nfilters_map.keys(), reverse=True, key=int)
        self.dropout_dims = self.dims[4:] 
        self.norm_dims = self.dims[2:]

        # dim reperesents the expected output dimension of the layers
        self.conv, self.conv_t = {}, {}
        for d, n_filters in self.dim_nfilters_map.items():
            self.conv[d] = tf.keras.layers.Conv2D(
                filters=n_filters, 
                kernel_size=kernel_size, 
                strides=2, 
                padding='same', 
                activation=activation_conv
            )
            # Upsample dim = downsample dim x 2, thus we skip the smallest dim
            if d != self.dims[-1]:
                self.conv_t[d] = tf.keras.layers.Conv2DTranspose(
                    filters=n_filters, 
                    kernel_size=kernel_size, 
                    strides=2, 
                    padding='same', 
                    activation=activation_conv_t
                )
        # Adds the last upsample layers
        self.conv_t['256'] = tf.keras.layers.Conv2DTranspose(
            filters=3,         # outputs an image with 3 channels
            kernel_size=kernel_size, 
            strides=2, 
            padding='same', 
            activation='sigmoid', # output range is from 0-1
        )

        # Adds dropout and layer normalization
        self.dropout = {
            d: tf.keras.layers.Dropout(rate=rate) for d in self.dropout_dims
        }
        self.norm = {
            d: tf.keras.layers.LayerNormalization() for d in self.norm_dims
        }

        self.dropout_t = {
            d: tf.keras.layers.Dropout(rate=rate) for d in self.dropout_dims
        }
        self.norm_t = {
            d: tf.keras.layers.LayerNormalization() for d in self.norm_dims
        }

    def call(self, x, training=False):
        # down-sample
        x_conv = {'256': x}
        for d in self.dims:
            x_conv[d] = self.conv[d](x_conv[str(int(d)*2)])

            if d in self.dropout_dims:
                x_conv[d] = self.dropout[d](x_conv[d], training=training)
            if d in self.norm_dims:
                x_conv[d] = self.norm[d](x_conv[d])

        # up-sample
        for d in self.dims[::-1]:
            if d == self.dims[-1]:
                concat_y = x_conv[d]
            else:
                concat_y = tf.keras.layers.Concatenate()([y, x_conv[d]])

            y = self.conv_t[str(int(d)*2)](concat_y)

            if d in self.dropout_dims:
                y = self.dropout_t[d](y, training=training)

            if d in self.norm_dims:
                y = self.norm_t[d](y)

        return y

    # Additional codes to print each step of the computational graph
    def view_model(self,):
        x = tf.keras.layers.Input(shape=(256, 256, 3))
        return tf.keras.Model(inputs=x, outputs=self.call(x))

"""Show examples of generated images with random initialization of trainable weights"""

generator = Generator()
y_pred = generator(x)

plots = {'x': x, 'y': y, 'y_pred': y_pred}

for i in range(len(x))[:2]:
    print('*'*100)
    plt.figure(figsize=(12, 3))
    for idx, (title, img) in enumerate(plots.items()):
        plt.subplot(1, 3, idx + 1)
        plt.imshow(img[i])
        plt.title(title)
    plt.subplots_adjust(wspace=0.3)
    plt.show()

"""Show the distribution of pixels in generated images"""

generator = Generator()
y_pred = generator(x)
plt.hist(tf.reshape(y_pred, (-1,)), bins=50); plt.show()

"""View the computational graph and the number of trainable parameters"""

generator = Generator()
tf.keras.utils.plot_model(generator.view_model(), show_shapes=True, dpi=45)

generator.view_model().summary()

"""## Discriminator

To train this generator, we construct a disciminator to tell us whether the generated images "look real".

Still find amazing that we can **quantify** the abstract concept of "look real" in mathematical terms.
"""

class Discriminator(tf.keras.Model):
    def __init__(self, rate=0.3):
        super().__init__()

        self.conv, self.norm, self.dropout = {}, {}, {}
        # We use 5 + 1 convolutional layers in total for the discriminator
        self.layer_names = [str(n) for n in range(5)]
        for i in self.layer_names:
            self.conv[i] = tf.keras.layers.Conv2D(
                filters=64 if int(i) < 3 else 256, 
                kernel_size=5, 
                strides=2 if int(i) < 3 else 1, 
                padding='same', 
                activation='relu',
            )
            self.dropout[i] = tf.keras.layers.Dropout(rate=rate)
            self.norm[i] = tf.keras.layers.LayerNormalization()

        self.zero_pad = tf.keras.layers.ZeroPadding2D()
        self.conv_0 = tf.keras.layers.Conv2D(filters=1, kernel_size=5, strides=1, activation='sigmoid')

    def call(self, x0, y0, training=False):
        x = tf.keras.layers.Concatenate()([x0, y0])
        for i in self.layer_names:
            x = self.norm[i](x)
            x = self.dropout[i](x, training=training)
            x = self.conv[i](x)
        x = self.zero_pad(x)
        return self.conv_0(x)

    # Additional codes to print each step of the computational graph
    def view_model(self,):
        x = tf.keras.layers.Input(shape=(256, 256, 3))
        y = tf.keras.layers.Input(shape=(256, 256, 3))
        return tf.keras.Model(inputs=[x, y], outputs=self.call(x, y))

"""Plot the distribution"""

discriminator = Discriminator()
d = discriminator(x, y)
loss= tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)
l0 = loss(tf.zeros_like(d), d)
l1 = loss(tf.ones_like(d), d)

plt.hist(tf.reshape(d, (-1,)), bins=50); plt.title('d output'); plt.show()
plt.hist(tf.reshape(l0, (-1,)), bins=50); plt.title('Loss 0'); plt.show()
plt.hist(tf.reshape(l1, (-1,)), bins=50); plt.title('Loss 1'); plt.show()

"""View the computational graph + the number of trainable weights"""

discriminator = Discriminator()
tf.keras.utils.plot_model(discriminator.view_model(), show_shapes=True, dpi=64)

discriminator.view_model().summary()

"""## Train Step

The train step follows the standard GAN training. I feel things are quite clean to wrap everything inside methods of a tf.keras.Model
"""

generator = Generator()
discriminator = Discriminator()

BCE_loss = tf.keras.losses.BinaryCrossentropy()

class GAN_model(tf.keras.Model):
    def __init__(self, dim_nfilters_map=dim_nfilters_map):
        super().__init__()
        self.generator = Generator(dim_nfilters_map=dim_nfilters_map)
        self.discriminator = Discriminator()
        self.loss_names = [
            'D_loss',
            'D_loss_true_images',
            'D_loss_gen_images',
            'G_loss',
            'G_loss_GAN',
            'G_loss_f1',]
        self.compile()

    def compile(self,):
        super().compile()
        self.optim_g = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
        self.optim_d = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

        self.metric = {}
        for loss_name in self.loss_names:
            self.metric[loss_name] = tf.keras.metrics.Mean(name=loss_name)


    @tf.function
    def train_step(self, data):

        x, y = data
        metric = {}

        with tf.GradientTape() as dtape, tf.GradientTape() as gtape:
            y_pred = self.generator(x, training=True)
            D_true = self.discriminator(x, y, training=True)
            D_gen = self.discriminator(x, y_pred, training=True)

            metric['G_loss_f1'] = tf.math.reduce_mean(tf.math.abs(y - y_pred))
            metric['G_loss_GAN'] = tf.math.reduce_mean(BCE_loss(tf.ones_like(D_gen), D_gen))
            metric['G_loss'] = metric['G_loss_GAN'] + 100 * metric['G_loss_f1']

            metric['D_loss_true_images'] = BCE_loss(tf.ones_like(D_true), D_true)
            metric['D_loss_gen_images'] = BCE_loss(tf.zeros_like(D_gen), D_gen)
            metric['D_loss'] = (metric['D_loss_true_images'] + metric['D_loss_gen_images']) / 2.0

        d_grads = dtape.gradient(metric['D_loss'], self.discriminator.trainable_variables)
        self.optim_d.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))

        g_grads = gtape.gradient(metric['G_loss'], self.generator.trainable_variables)
        self.optim_g.apply_gradients(zip(g_grads, self.generator.trainable_variables))

        # Update metrics and output the average results
        for loss_name in self.loss_names:
            self.metric[loss_name].update_state(metric[loss_name])

        return {
            loss_name: self.metric[loss_name].result() for loss_name in self.loss_names
        }

"""# Image to Image Models

## Tensorboard

Call the tensorboard to view the training progress
"""

log_dir = 'logs/fit/'

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir {log_dir}

"""## Callbacks

We visualize the prediction of the generator on the validation set after the end of each epoch
"""

class Visualize_callback(tf.keras.callbacks.Callback):
    def __init__(self,):
        super().__init__()
        self.iter = iter(val_ds.repeat().batch(1))

    def on_epoch_end(self, epoch, logs=None):
        x, y = self.iter.get_next()
        y_pred = self.model.generator(x)

        plots = {'x': x, 'y': y, 'y_pred': y_pred}

        plt.figure(figsize=(12, 3))
        for idx, (title, img) in enumerate(plots.items()):
            plt.subplot(1, 3, idx + 1)
            plt.imshow(img[0])
            plt.title('%s (%s)' %(title,epoch))
        plt.subplots_adjust(wspace=0.3); plt.show()

"""## Train the Image-to-Image translation model"""

dim_nfilters_map = {128: 32, 64: 64, 32: 128, 16: 256, 8: 256, 4: 256, 2:256, 1: 256}
model = GAN_model(dim_nfilters_map=dim_nfilters_map)
model.generator.view_model().summary()

# Declares all the callbacks
visualize_callback = Visualize_callback()
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

checkpoint_path = "training/cp.ckpt"
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 monitor='G_loss',
                                                 verbose=1)

model.fit(train_ds.shuffle(500).batch(2), epochs=250, callbacks=[visualize_callback, tensorboard_callback, cp_callback])

"""# Generate Images

Load the best performing epoch and translate from images to images
"""

# Create a model and restore from the best checkpoint
model = GAN_model()

checkpoint = tf.train.Checkpoint(model)
checkpoint.restore(checkpoint_path)

# Translate from images to images
for x, y in test_ds.batch(1).take(5):
    print('*'*100)
    y_pred = model.generator(x, training=False)
    plots = {'x': x, 'y': y, 'y_pred': y_pred}
    plt.figure(figsize=(12, 3))
    for idx, (title, img) in enumerate(plots.items()):
        plt.subplot(1, 3, idx + 1)
        plt.imshow(img[0])
        plt.title(title)
    plt.subplots_adjust(wspace=0.3)
    plt.show()

for x, y in test_ds.batch(1).take(5):
    print('*'*100)
    y_pred = model.generator(x, training=False)
    plots = {'x': x, 'y': y, 'y_pred': y_pred}
    plt.figure(figsize=(12, 3))
    for idx, (title, img) in enumerate(plots.items()):
        plt.subplot(1, 3, idx + 1)
        plt.imshow(img[0])
        plt.title(title)
    plt.subplots_adjust(wspace=0.3)
    plt.show()

for x, y in test_ds.batch(1).take(5):
    print('*'*100)
    y_pred = model.generator(x, training=False)
    plots = {'x': x, 'y': y, 'y_pred': y_pred}
    plt.figure(figsize=(12, 3))
    for idx, (title, img) in enumerate(plots.items()):
        plt.subplot(1, 3, idx + 1)
        plt.imshow(img[0])
        plt.title(title)
    plt.subplots_adjust(wspace=0.3)
    plt.show()

for x, y in test_ds.batch(1).take(5):
    print('*'*100)
    y_pred = model.generator(x, training=False)
    plots = {'x': x, 'y': y, 'y_pred': y_pred}
    plt.figure(figsize=(12, 3))
    for idx, (title, img) in enumerate(plots.items()):
        plt.subplot(1, 3, idx + 1)
        plt.imshow(img[0])
        plt.title(title)
    plt.subplots_adjust(wspace=0.3)
    plt.show()

"""Cool. We are now at the end of the notebook. Thank you for reading the implementation."""